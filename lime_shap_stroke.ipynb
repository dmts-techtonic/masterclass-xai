{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "antique-motel",
   "metadata": {
    "id": "b89570e9"
   },
   "source": [
    "# LIME and SHAP Hands-on exercise\n",
    "Welcome to the hands-on exercise for the DMTS Master Class on Explanable AI using LIME and SHAP frameworks.\n",
    "\n",
    "This assignment uses Stroke Prediction Dataset that is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status or not. The dataset is available at https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n",
    "\n",
    "Attribute Information\n",
    "1. id: unique identifier\n",
    "2. gender: \"Male\", \"Female\" or \"Other\"\n",
    "3. age: age of the patient\n",
    "4. hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
    "5. heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
    "6. ever_married: \"No\" or \"Yes\"\n",
    "7. work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
    "8. Residence_type: \"Rural\" or \"Urban\"\n",
    "9. avg_glucose_level: average glucose level in blood\n",
    "10. bmi: body mass index\n",
    "11. smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
    "12. stroke: This is the output, which indicates if the person has Stroke or not. 1 if the patient had a stroke or 0 if not\n",
    "\n",
    "*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient\n",
    "\n",
    "The first few steps transforms the dataset into a form that is more efficient for Machine Learning. Then a Random Forest Classifier model is trained and validated. The result of the predictions are then analyzed using both LIME and SHAP libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913b76a",
   "metadata": {},
   "source": [
    "### 1 - Import Packages\n",
    "First import all the packages that you will need during this assignment.\n",
    "\n",
    "* pandas is the Python-based data analysis toolkit\n",
    "* numpy is the fundamental package for scientific computing with Python\n",
    "* matplotlib is a library for plotting graphs in Python\n",
    "* seaborn is a data visualization library built on top of Matplotlib\n",
    "* interpret (InterpretML) is an open-source Python package which exposes machine learning interpretability algorithms\n",
    "* imblearn is a library to generate data to overcome imbalanced dataset\n",
    "\n",
    "If you are using Google colab, it is likely that interpret and imblearn are not pre-installed. The below steps first attempts to import interpret and imblearn. If it is not found, it attempts to install. \n",
    "You might receive Warning on incompatability of few libraries. We can ignore it, as it does not impact this exercise. The runtime has to be restarted either by clicking on 'Restart Runtime' that is displayed in the out of the cell or from top menu select “Runtime” -> Restart Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-presentation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dff348ae",
    "outputId": "8a266188-c2c0-4f1b-8069-457321bd8b01"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#!pip install interpret if not found\n",
    "try:\n",
    " import interpret\n",
    "except:\n",
    "  print(\"Installing interpret ML\")\n",
    "  !pip install interpret\n",
    "\n",
    "\n",
    "try:\n",
    "  import imblearn\n",
    "except:\n",
    "  print(\"Installing imblearn\")\n",
    "  !pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e3730",
   "metadata": {},
   "source": [
    "### 2. Read the dataset\n",
    "The below step loads the dataset which is a copy from Kaggle (https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)\n",
    "Once loaded the first few records are printed with the column names. Please observe the features in the form of columns and the values.\n",
    "\n",
    "Please note: If you get the error \"name 'pd' is not defined\" please rerun the above cell and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-ordinary",
   "metadata": {
    "id": "ec99222b"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/dmts-techtonic/masterclass-xai/main/healthcare-dataset-stroke-data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31389b0",
   "metadata": {},
   "source": [
    "### 3. Analyze the data type\n",
    "The info() method on the dataframe prints the data type of each of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-headquarters",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "c1d78543",
    "outputId": "bc11f46b-8cdf-44be-f9eb-739d7ebdef03"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b86c4e",
   "metadata": {},
   "source": [
    "### 4. Converting Categorical features\n",
    "As you would have observed the features 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status' are non-numerical. Machine learning algorithms are good at dealing with numeric values. There are different ways to convert Categorical values to numerical. One-hot encoding technique is used below, where the each categorical value is converted into a new column (also called dummy column) and assign a binary value of 1 or 0 to those columns. Once converted the original non-numerical column is dropped. Observe the converted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-permit",
   "metadata": {
    "id": "773a665d"
   },
   "outputs": [],
   "source": [
    "# One-hot encode all categorical columns\n",
    "categorical_cols = [\"gender\",\n",
    "                        \"ever_married\",\n",
    "                        \"work_type\",\n",
    "                        \"Residence_type\",\n",
    "                        \"smoking_status\"]\n",
    "\n",
    "encoded = pd.get_dummies(df[categorical_cols], \n",
    "                        prefix=categorical_cols)\n",
    "\n",
    "# Update data with new columns\n",
    "df = pd.concat([encoded, df], axis=1)\n",
    "df.drop(categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Impute missing values of BMI\n",
    "df.bmi = df.bmi.fillna(0)\n",
    "\n",
    "# Drop id as it is not relevant\n",
    "df.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0e251",
   "metadata": {},
   "source": [
    "### 5. Split Dataset for Training and Validation\n",
    "The dataset is split between Training and Validation/Test in the ratio of 80:20. To keep the exercise simple, the original dataset is split into 2 instead of 3 separate sets for Training, Validation and Test. Hence the validation and test datasets are the same. \n",
    "\n",
    "The label column 'stroke' is extracted into result Dataframe and removed from both the training and validation data. \n",
    "Observe the total number of number of records in the Training and Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-filename",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59fad8c5",
    "outputId": "0433ceee-ac72-4383-b954-d3488c2d4518"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('stroke',axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=30)\n",
    "\n",
    "print(\"Training Data : {} Features, {} Records\".format(X_train.shape[1], X_train.shape[0]))\n",
    "print(\"Validation Data : {} Features, {} Records\".format(X_test.shape[1], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb07415",
   "metadata": {},
   "source": [
    "### 6. Feature scaling\n",
    "Several Machine learning algorithms work efficiently if values of all the features are comparable and within similar range. In the below step MinMaxScaler is applied to normalize the feature values to the training and validation data.\n",
    "In this exercise, we are going to skip the Feature scaling, and retain the original feature value so that during explainability it will be easy to relate to the original feature value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-shell",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "0fca9e62",
    "outputId": "890aadfe-87d6-45c7-f4c0-3b1e6e532789"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e40a945",
   "metadata": {},
   "source": [
    "### 7. View imbalance of Label data\n",
    "The below step displays the number of occurrences when the patient had stroke vs no stroke in the given dataset. Please observe the count when stroke is 0 and when stroke is 1. The number of records with stroke is lot less when compared to no stroke. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-sleep",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4611a939",
    "outputId": "7b42b3ee-a24e-40fa-a2af-832751345960"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51131e8",
   "metadata": {},
   "source": [
    "### 8. Balance the data using Oversampling\n",
    "As seen above, the training with such skewed test data may not be optimal. In order to balance the data Random Over Sampling technique is used. The RandomOverSampler duplicates some of the original samples having stroke '1'. Observe the result after oversampling.\n",
    "The dataset is ready for training now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-pathology",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57c6b424",
    "outputId": "5ef7d59b-1854-47e5-e14b-6dcaa03a04e4"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf5d65",
   "metadata": {},
   "source": [
    "### 9. Model Creation and Training\n",
    "The below steps creates Random Forest Classifier model, trains the model using the training data and then using the trained model, predicts the result for the validation data.\n",
    "\n",
    "Random forests Classification algorithm is used in the exercise as it is a good representative \"blackbox\" model and also gives resonable good model performance. Any other algorithm also can be used for LIME and SHAP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-identification",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4149e792",
    "outputId": "b04c0dc8-295f-480f-b6f9-f57875fe9265"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# %% Fit blackbox model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train.values, y_train.values)\n",
    "y_pred = rf.predict(X_test.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817d33f",
   "metadata": {},
   "source": [
    "### 10. Model Performance\n",
    "Congratulations! with the completion of the above step, you have successfully trained a Machine Learning Model. \n",
    "Let us see the performance of the model by comparing the predicted values against the actual result of the validation/test data. The Accuracy and F1 score of the model is printed, along with the Confusion matrix that was used to calculate them.\n",
    "\n",
    "You may be getting accuracy of 95% and F1 score of 0.54.  To keep the exercise simple, no hyperparameters tuning is done.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score {f1_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"Accuracy {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# print(classification_report(y_test,y_pred))\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fceae03",
   "metadata": {},
   "source": [
    "### 11. Feature Importance\n",
    "Now that the model has been trained and validated, let us see the importance of each of the features to understand how the model works. As it can be seen age, avg_glucose_level, bmi have high importance when compared to other features. While the feature importance gives the overall influence of the features, in order to get more insight on the influence of features for specific sample, LIME and SHAP can be used that are covered in the next steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "feat_importances.nlargest(25).plot(kind='barh',figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563fd0d8",
   "metadata": {},
   "source": [
    "# LIME - Local Interpretable Model Agnostic Explanations\n",
    "The below few steps use LIME to explain the model prediction for Random Forest model created in the earlier step. As discussed in the theory session LIME is used to explain complex non-linear models with simple surrogate models. LIME is model agnostic and can be used for model created using any algorithm beyond Random Forest used in this exercise. LIME explains the classifier for a specific single instance and is therefore suitable for local consideration.\n",
    "The research  paper “Why Should I Trust You? Explaining the Predictions of Any Classifier\" by Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin describes in detail the mathematical modeling and internal working of LIME to explain the prediction. Fortunately the LIME libraries that we use below abstract the mathematical modeling and simplifies the usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c31425",
   "metadata": {},
   "source": [
    "### 12. Initialize LIME for Tabular data using InterpretML\n",
    "The below step initializes LIME for Tabular data analysis. It uses interpretML library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-wisdom",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "08b3aad8",
    "outputId": "04f92c74-8078-4185-c3c7-170818e80d54"
   },
   "outputs": [],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "from interpret import show\n",
    "\n",
    "# %% Apply lime\n",
    "# Initilize Lime for Tabular data\n",
    "lime = LimeTabular(predict_fn=rf.predict_proba, \n",
    "                   data=X_train,\n",
    "                   feature_names=df.drop('stroke',axis=1).columns.tolist(),\n",
    "                   random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a73ac8",
   "metadata": {},
   "source": [
    "### 13. Get Local Explanations for individual samples\n",
    "Once LIME Tabular has been initialized, it can be used to explain the prediction for specific samples. \n",
    "The below step executes location explanations for samples with index 0 to 19. It may take more than a minute to complete. Ignore the warnings. Once complete, it will display drop down with predictions for each of the 20 samples. Selecting a particular sample in the drop down, will display the local explanations for the prediction for the paricular sample. \n",
    "Observe the predictions. \n",
    "\n",
    "In order to deep dive let us pick 2 examples with one where the model classifies as 'Stroke' and another where the model classifies as 'No Stroke'. \n",
    "\n",
    "The record in dropdown with index 0 has prediction for Stroke and may look like -  '0: Predicted (0.6) | Actual (1.0)' | Resid (0.4)'. \n",
    "The model has predicted 'Stroke' with probability around 0.6 and 'No Stroke' with probability around 0.4. Observe the individual features contributing to positive Stroke and negative Stroke. The features in the right side in Orange color are the ones that are contributing to Stroke and the features in the left side in Blue color are the ones contributing to 'No Stroke'. As you can see, the features contributing to 'Stroke' is higher than the ones contributing to 'No Stroke'\n",
    "\n",
    "The record in dropdown with index 1 has prediction for 'No Stroke' -  '1: Predicted (0.01) | Actual (0)' | Resid (-0.01)'. \n",
    "The model has predicted 'No Stroke' with probability around 0.9x and 'Stroke' with probability around 0.0x. Observe the individual features contributing to 'No Stroke' and 'Stroke'. As you can see, the features contributing to 'No Stroke' (left side - Blue) is lot more than the ones contributing to 'Stroke' (right side - Orange)\n",
    "\n",
    "Please ignore UserWarning, if any related to deprecated package usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c623e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get local explanations\n",
    "lime_local = lime.explain_local(X_test[0:20], \n",
    "                                y_test[0:20], \n",
    "                                name='LIME')\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854623a",
   "metadata": {},
   "source": [
    "### 14. Initiate LIME using lime library\n",
    "The below step initializes LIME for Tabular data analysis using Lime library instead of the interpretML library. It shows different representation of the same data. You may chose either the above interpretML's visualization or the below view, whichever is more comprehensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer( training_data = np.array(X_train), feature_names=X_train.columns,class_names=['0 - No Stroke','1 - Stroke'],mode='classification')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242768b",
   "metadata": {},
   "source": [
    "### 15. Visualize local explanations using LIME for Classification 1 - Stroke\n",
    "In the below step, local explanation is done for index 0, which is predicted as 'Stroke' candidate. The model has predicted 'Stroke' with probability around 0.6 and 'No Stroke' with probability around 0.4. Observe the individual features contributing to positive Stroke and negative Stroke. The features in the right side in Orange color are the ones that are contributing to Stroke and the features in the left side in Blue color are the ones contributing to 'No Stroke'. As you can see, the features contributing to 'Stroke' is higher than the ones contributing to 'No Stroke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_index = 0\n",
    "l=X_test.iloc[record_index, :]\n",
    "exp = explainer.explain_instance(data_row=l, predict_fn = rf.predict_proba)\n",
    "# print(l)\n",
    "print('Actual outcode:' + str(y_test.iloc[record_index]))\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd404d89",
   "metadata": {},
   "source": [
    "### 16. Visualize local explanations using LIME for Classification 0 - No Stroke\n",
    "In the below step, local explanation is done for index 1, which is predicted as 'No Stroke' candidate. \n",
    "\n",
    "The model has predicted 'No Stroke' with probability around 0.95 and 'Stroke' with probability around 0.05. Observe the individual features contributing to positive Stroke and negative Stroke. The features in the right side in Orange color are the ones that are contributing to Stroke and the features in the left side in Blue color are the ones contributing to 'No Stroke'. As you can see, the features contributing to 'No Stroke' (left side - Blue color) is higher than the ones contributing to 'Stroke' (right side - Orange color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_index = 1\n",
    "l=X_test.iloc[record_index, :]\n",
    "exp = explainer.explain_instance(data_row=l, predict_fn = rf.predict_proba)\n",
    "# print(l)\n",
    "print('Actual outcode:' + str(y_test.iloc[record_index]))\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970562f",
   "metadata": {},
   "source": [
    "# SHAP - SHapley Additive exPlanation\n",
    "SHapley Additive exPlanation, acronymed SHAP, is another model agnostic technique used to explain predictions like LIME. SHAP is based on game theory concept created by Lloyd Stowell Shapley in 1950s. It was originally used to find the marginal contribution of each of the individual players in a coalition of players, so that a lumpsum of price money can be distributed among the players according to their contribution, instead of equal split. The contribution of each player is quantified as Shapley value.\n",
    "\n",
    "Machine learning prediction is considered as a game. Features are players playing together to bring an outcome (prediction). SHAP is used to calculate the average marginal contribution of a feature value over all possible coalitions of features. The details of the mathematical model behind SHAP is explained in the research paper \"A Unified Approach to Interpreting Model Predictions\" by Scott Lundberg and Su-In Lee. Fortunately we do not have to implement the mathematical model ourselves. The SHAP library used below abstracts the mathematical model and simplifies the usage.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523e855",
   "metadata": {},
   "source": [
    "### 17. Create SHAP Explainer\n",
    "The below step creates SHAP explainer using TreeExplainer. The explainer instance will be used in subsequent steps to explain SHAP values.\n",
    "\n",
    "TreeExplainer is a fast and accurate algorithm used in all kinds of tree-based models like Random Forests. SHAP also has DeepExplainer for Deep learning models and KernelExplainer for any machine learning regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-lesbian",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "4fd2c7b9",
    "outputId": "3327abd1-921b-4167-ceae-2f6c2f1d3166"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# %% Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21ec01",
   "metadata": {},
   "source": [
    "### 18. Select record for explainability using SHAP for Classification 1 - Stroke\n",
    "In the below step, the record with index 0 is selected for explaining using SHAP. This is the same record that was earlier analyzed using LIME as well, which is predicted as 'Stroke' candidate with probability around 0.6. \n",
    "\n",
    "The values of the features for that record is displayed for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595cdf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate shapley values for test data\n",
    "record_index = 0\n",
    "end_index = record_index + 1  # to analyze 1 sample record. \n",
    "X_test[record_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69389f",
   "metadata": {},
   "source": [
    "### 19. Print Shapley values\n",
    "The below step displays the Shapley values for the selected record. It gives Shapley values for each feature for either of the Classifications i.e. for predicting 'No Stroke' and 'Stroke'. Observe how for each feature the Shapley values negates between the mutually exclusive classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dc6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test[record_index:end_index])\n",
    "\n",
    "# class 0 = contribution to No Stroke\n",
    "# class 1 = contribution to Stroke\n",
    "# creating temporary Dataframe to view Shapley value in readable table\n",
    "temp_df = pd.DataFrame(shap_values[0].T, X_test.columns, ['Shapley values for No Stroke'])\n",
    "temp_df['Shapley values for Stroke'] = shap_values[1].T\n",
    "temp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a16962",
   "metadata": {},
   "source": [
    "### 20. Visualize the Shapley values for Classification 1 - Stroke\n",
    "While the above step displayes the quantified Shapley values, it may not be very helpful in appreciating the relative comparison. In the below step, we sill visualize the Shapley values for the selected record. Observe individual features contributing to the prediction.\n",
    "\n",
    "For this record, the overall prediction of 'Stroke' is around 0.6x. The features in the left side, in red color, contribute to 'Stroke'. The features in the right side, in blue color, contribute to 'no Stroke'. The width of each feature is its Shapley value and the total width is the cummulative Shapley values for all the attributes favoring the particular classification. In this case the Shapley values of the features contributing to Stroke is higher compared to the Shapley values of features contributing to 'no Stroke'. Hence the prediction was made as 'Stroke'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "prediction = rf.predict(X_test[record_index: end_index])[0]\n",
    " \n",
    "shap.force_plot(explainer.expected_value[1],\n",
    "                shap_values[1],\n",
    "                X_test[record_index: end_index]) # for values\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Repeat the visualization for a different sample with Classification 0 - No Stroke\n",
    "\n",
    "The below step visualizes for a different sample with index '1' which has prediction as '0 - No Stroke'. In order to visualize the feature contributions to Classification 0, while plotting the graph, Shapley values in array index '0' in variable 'shap_values' is taken, unlike the earlier example where the contributions to Classification 1 was visualized.\n",
    "\n",
    "The below graph shows the prediction of 'No Stroke' with probability of around 0.95 and the features in the left side in red color contribute to it and the ones against it in Blue color. You can notice that unlike the earlier example, in this case the Age feature is contributing to 'No Stroke'. \n",
    "\n",
    "Try changing the record_index and end_index to different values and observe the Shapley value contributions for that particular record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_index = 1\n",
    "end_index = record_index + 1  # to analyze 1 sample record. \n",
    "shap_values = explainer.shap_values(X_test[record_index:end_index])\n",
    "\n",
    "shap.initjs()\n",
    "prediction = rf.predict(X_test[record_index:end_index])[0]\n",
    "\n",
    "# print(f\"The predicted value: {prediction}\")\n",
    "shap.force_plot(explainer.expected_value[1],\n",
    "                shap_values[0],\n",
    "                X_test[record_index:end_index]) # for values\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe4ab1",
   "metadata": {},
   "source": [
    "### 22. Visualize Shepley values for group of records\n",
    "In the below step, 20 records from index 0 to 19 are analyzed. \n",
    "\n",
    "The graph has drop downs in both the dimensions. By default 'sample order by similarity' is selected in the dropdown for the X Axis that shows the instance index and for dropdown in Y axis, the Shapley values (function f(x)) is defaulted. On mouse over in the graph, the particular instance's feature values and the overall Shapley values are highlighted.\n",
    "\n",
    "Explore the visualization by changing the dropdown values. First you can try changing the value in the dropdown in Y axis to see the effect of individual feature for each of the instance. \n",
    "For example, to understand the impact of feature age, select 'age' in the dropdown in Y axis. You can see that higher the age, the chances of stroke is higher. Similarly you can try checking for other features. You can also change the dropdown in X axis and visualize the impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-tournament",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "5575540d",
    "outputId": "04ceb269-ce83-4c04-c9b9-eda729b3a1db"
   },
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 20\n",
    "shap_values = explainer.shap_values(X_test[start_index:end_index])\n",
    "shap.initjs()\n",
    "prediction = rf.predict(X_test[start_index:end_index])[0]\n",
    "# print(f\"The RF predicted: {prediction}\")\n",
    "shap.force_plot(explainer.expected_value[1],\n",
    "                shap_values[1],\n",
    "                X_test[start_index:end_index]) # for values\n",
    "# shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145d5e3",
   "metadata": {},
   "source": [
    "### 23. Visualize Global Features\n",
    "The below step displays the summary plot for the 20 instances. As you can see the features age, avg_glucose_level, bmi play vital role in selecting Class 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-shift",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "65f529fa",
    "outputId": "b06acc5e-4c15-45ad-e0aa-5a326881e709"
   },
   "outputs": [],
   "source": [
    "# %% >> Visualize global features\n",
    "# Feature summary\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8d8fd",
   "metadata": {},
   "source": [
    "#### Congratulations!  You have successfully analyzed the predictions of model using LIME and SHAP explainable AI libraries \n",
    "\n",
    "Possible next step for learning:\n",
    "* You can try changing Randow Forest Classifier to other algorithms and try the same exercise\n",
    "* You can try using a different dataset and try the same exercise using LIME and SHAP\n",
    "* You can try to apply LIME over multiclass textual data of newsgroup dataset by using the following link https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html\n",
    "* You can try to apply SHAP for Sentiment Analysis with Logistic Regression on IDMB dataset by using the following link https://slundberg.github.io/shap/notebooks/linear_explainer/Sentiment%20Analysis%20with%20Logistic%20Regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9922d32",
   "metadata": {},
   "source": [
    "Reference for above exercise: 'Learn XAI in Simplified way by Prof.Prateek Bhatia' in Udemy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lime-shap-stroke.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "803241e9d59b415c95677c4d4170403d36cdf348c05c37efc3ee93617632cbda"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
